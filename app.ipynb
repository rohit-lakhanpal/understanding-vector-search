{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searcing across Elastic, Azure Search (basic), Azure Search (semantic), and Azure Search (embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Search\n",
    "\n",
    "### Setup\n",
    "Ensure you have a docker daemon running. Then run the following commands to start an instance of Elastic Search.\n",
    "```sh\n",
    "docker network create es-net-01\n",
    "\n",
    "docker pull docker.elastic.co/elasticsearch/elasticsearch:8.8.2\n",
    "docker run -d --name es-node-01 --net es-net-01 -p 9200:9200 -p 9300:9300 \\\n",
    "           -e \"discovery.type=single-node\" \\\n",
    "           -e \"xpack.security.enabled=false\" \\\n",
    "           -e \"http.cors.enabled=true\" \\\n",
    "           -e \"http.cors.allow-origin=http://localhost:8080\" \\\n",
    "           docker.elastic.co/elasticsearch/elasticsearch:8.8.2\n",
    "\n",
    "docker pull cars10/elasticvue\n",
    "docker run --name es-ui --net es-net-01 -p 8080:8080 -d cars10/elasticvue\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for elastic search\n",
    "%pip install elasticsearch\n",
    "%pip install python-dotenv\n",
    "%pip install azure-search --pre\n",
    "%pip install azure-search-documents --pre\n",
    "%pip install azure-core\n",
    "%pip install pandas\n",
    "%pip install openai\n",
    "%pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Read the data.csv file we will use in this example\n",
    "dataset = pd.read_csv('data.csv')\n",
    "dataset = dataset.to_json(orient='records')\n",
    "dataset = json.loads(dataset)\n",
    "\n",
    "\n",
    "# Pretty print the data we will be indexing\n",
    "pprint(dataset, indent=2, sort_dicts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Populate\n",
    "Create an index & populate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Connect to the elastic search cluster at localhost:9200 with no authentication\n",
    "es = Elasticsearch(['http://localhost:9200/'])\n",
    "\n",
    "# Check that the cluster is up and running\n",
    "es.ping()\n",
    "\n",
    "# Create an index called animals\n",
    "es_index_name = 'animals'\n",
    "\n",
    "# Display error message if the cluster is not up and running\n",
    "if not es.ping():    \n",
    "    raise ValueError('Connection failed. Check if the container is running ')\n",
    "else:\n",
    "    # try to create an index called animals\n",
    "    try:\n",
    "        # Check if an index called animals exists, if it does delete it and then create a new one\n",
    "        if es.indices.exists(index=es_index_name):\n",
    "            es.indices.delete(index=es_index_name)\n",
    "            es.indices.create(index=es_index_name)\n",
    "        else:\n",
    "            es.indices.create(index=es_index_name)\n",
    "\n",
    "        # Load the dataset into the index\n",
    "        for i in range(len(dataset)):\n",
    "            es.index(index=es_index_name, id=dataset[i]['id'], document=dataset[i])\n",
    "    except:\n",
    "        raise "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "def perform_es(query):\n",
    "    print('Searching for documents with query: ', query)\n",
    "    results = es.search(index=es_index_name, q=query)\n",
    "    pprint(results['hits']['hits'], indent=4, sort_dicts=False)\n",
    "\n",
    "perform_es('Oct*')\n",
    "perform_es('*has tentacles*')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Search\n",
    "\n",
    "### Setup\n",
    "Follow these instructions to create an Azure Search instance. https://learn.microsoft.com/en-us/azure/search/search-create-service-portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (\n",
    "    CorsOptions,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SearchFieldDataType,\n",
    "    SearchField,    \n",
    "    SimpleField,  \n",
    "    SearchableField, \n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSettings,\n",
    ")\n",
    "\n",
    "from azure.core.exceptions import (\n",
    "    ResourceNotFoundError\n",
    ")\n",
    "\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    ")  \n",
    "    \n",
    "\n",
    "# Get the service name (short name) and admin API key from the environment\n",
    "service_name = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "endpoint = \"https://{}.search.windows.net/\".format(service_name)\n",
    "\n",
    "# Create a service client\n",
    "azure_search_client = SearchIndexClient(endpoint, AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Search (Basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Populate Index (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic search index\n",
    "basic_index_name = \"animals-index-basic\"\n",
    "basic_index = SearchIndex(\n",
    "    name = basic_index_name,\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"name\", type=SearchFieldDataType.String),        \n",
    "        SearchableField(name=\"animal\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"song\", type=SearchFieldDataType.String)\n",
    "    ],\n",
    "    scoring_profiles = [],\n",
    "    cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\n",
    ")\n",
    "\n",
    "\n",
    "# Create an index\n",
    "try:\n",
    "    # Check if an index called animals exists, if it does delete it and then create a new one\n",
    "    if azure_search_client.get_index(basic_index_name):\n",
    "        azure_search_client.delete_index(basic_index_name)\n",
    "\n",
    "except:\n",
    "    if ResourceNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    azure_search_client.create_index(basic_index)\n",
    "    searchClient = SearchClient(endpoint, basic_index_name, AzureKeyCredential(key))\n",
    "\n",
    "    # modify dataset such that all id fields are strings\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]['id'] = str(dataset[i]['id'])\n",
    "        searchClient.upload_documents(documents=[dataset[i]])\n",
    "except:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search and Print (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_basic_search(query):\n",
    "    print('Searching for documents with query: ', query)\n",
    "\n",
    "    # Call the search method on the search client and pass in the query\n",
    "    results = searchClient.search(search_text=query)\n",
    "    # Iterate over the results and print the document id and the text score\n",
    "    for result in results:\n",
    "        print('Document id: ', result['id'], ' Score: ', result['@search.score'])\n",
    "        pprint(result, indent=4)\n",
    "    if results.get_count() == None or results.get_count() == 0:\n",
    "        print('No results found')\n",
    "\n",
    "\n",
    "perform_basic_search('Oct*')\n",
    "perform_basic_search('has tentacles*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Search (Semantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Populate Index (Semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_index_name = \"animals-index-semantic\"\n",
    "semantic_config_name = \"my-semantic-config\"\n",
    "semantic_index = SearchIndex(\n",
    "    name = semantic_index_name,\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"name\", type=SearchFieldDataType.String),        \n",
    "        SearchableField(name=\"animal\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"song\", type=SearchFieldDataType.String)\n",
    "    ],\n",
    "    scoring_profiles = [],\n",
    "    cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60),\n",
    "    semantic_settings = SemanticSettings(configurations=[SemanticConfiguration(\n",
    "        name=semantic_config_name,\n",
    "        prioritized_fields=PrioritizedFields(\n",
    "            # A title field should be a concise description of the document, \n",
    "            # ideally a string that is under 25 words. \n",
    "            # This could be the title of the document, name of the product, \n",
    "            # or item in your search index. If you don't have a title in \n",
    "            # your search index, leave this field blank.\n",
    "            # In this case the title field will be animal as it describes the type.\n",
    "            title_field=SemanticField(field_name=\"animal\"),\n",
    "            # Kevword fields should be a list of keywords. such as the tags on a document, \n",
    "            # or a descriptive term. such as the category of an item. \n",
    "            # Make sure to list kevword fields in order of priority because lower priority \n",
    "            # fields mav aet truncated or janored.\n",
    "            prioritized_keywords_fields=[SemanticField(field_name=\"name\")],\n",
    "            prioritized_content_fields=[SemanticField(field_name=\"song\")]\n",
    "        )\n",
    "    )])\n",
    ")\n",
    "\n",
    "\n",
    "# Create an index\n",
    "try:\n",
    "    # Check if an index called animals exists, if it does delete it and then create a new one\n",
    "    if azure_search_client.get_index(semantic_index_name):\n",
    "        azure_search_client.delete_index(semantic_index_name)\n",
    "\n",
    "except:\n",
    "    if ResourceNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    azure_search_client.create_index(semantic_index)\n",
    "    semantic_search_client = SearchClient(endpoint, semantic_index_name, AzureKeyCredential(key))\n",
    "\n",
    "    # modify dataset such that all id fields are strings\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]['id'] = str(dataset[i]['id'])\n",
    "        semantic_search_client.upload_documents(documents=[dataset[i]])\n",
    "except:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search and Print (Semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_semantic_search(query):\n",
    "    print('Searching for documents with query: ', query)\n",
    "\n",
    "    semantic_search_client = SearchClient(endpoint, semantic_index_name, AzureKeyCredential(key))\n",
    "\n",
    "    results = semantic_search_client.search(search_text=query, semantic_configuration_name=semantic_config_name)\n",
    "\n",
    "    # print message if no results are found\n",
    "    if results.get_count() == None or results.get_count() == 0:\n",
    "        print('No results found')\n",
    "\n",
    "    for result in list(results):\n",
    "        print('Document id: ', result['id'], ' Score: ', result['@search.score'])\n",
    "        pprint(result, indent=4)\n",
    "\n",
    "\n",
    "perform_semantic_search('Oct*')\n",
    "perform_semantic_search('has tentacles')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Search (Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANIZATION\") \n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  \n",
    "# openai.api_type = \"azure\"  \n",
    "# openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "# openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "# openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "\n",
    "# Import required libraries  \n",
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  \n",
    "  \n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Generate embeddings for the dataset\n",
    "for i in range(len(dataset)):\n",
    "    animal_embeddings = generate_embeddings(dataset[i]['animal'])\n",
    "    # song_embeddings = generate_embeddings(dataset[i]['song'])\n",
    "    name_embeddings = generate_embeddings(dataset[i]['name'])\n",
    "    # dataset[i]['animal_embeddings'] = animal_embeddings\n",
    "    dataset[i]['animalVector'] = animal_embeddings\n",
    "    # dataset[i]['song_embeddings'] = song_embeddings\n",
    "    # dataset[i]['songVector'] = song_embeddings\n",
    "    # dataset[i]['name_embeddings'] = name_embeddings\n",
    "    dataset[i]['nameVector'] = name_embeddings\n",
    "\n",
    "# print the dataset with the embeddings (only top 1)\n",
    "pprint(dataset, indent=0, sort_dicts=False, width=100)\n",
    "\n",
    "\n",
    "# import os  \n",
    "# import json  \n",
    "# import openai  \n",
    "# from dotenv import load_dotenv  \n",
    "# from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "# from azure.search.documents.indexes.models import (  \n",
    "     \n",
    "#     SemanticConfiguration,  \n",
    "#     PrioritizedFields,  \n",
    "#     SemanticField,    \n",
    "#     SemanticSettings,  \n",
    "#     VectorSearch,  \n",
    "#     VectorSearchAlgorithmConfiguration,  \n",
    "# ) \n",
    "\n",
    "# # See: https://github.com/Azure/cognitive-search-vector-pr/blob/main/demo-python/code/azure-search-vector-python-sample.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_name = \"animals-index-vector\"\n",
    "vector_semantic_config_name = \"my-vector-semantic-config\"\n",
    "vector_config_name = \"my-vector-config\"\n",
    "vector_fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"name\", type=SearchFieldDataType.String),        \n",
    "        SearchableField(name=\"animal\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"song\", type=SearchFieldDataType.String),\n",
    "        SearchField(name=\"nameVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=vector_config_name),\n",
    "        SearchField(name=\"animalVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=vector_config_name),\n",
    "        # SearchField(name=\"songVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        #         searchable=True, vector_search_dimensions=1536, vector_search_configuration=vector_config_name),\n",
    "    ]\n",
    "vector_index = SearchIndex(\n",
    "    name = vector_index_name,\n",
    "    fields = vector_fields,\n",
    "    scoring_profiles = [],\n",
    "    cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60),\n",
    "    semantic_settings = SemanticSettings(configurations=[SemanticConfiguration(\n",
    "        name=vector_semantic_config_name,\n",
    "        prioritized_fields=PrioritizedFields(\n",
    "            # A title field should be a concise description of the document, \n",
    "            # ideally a string that is under 25 words. \n",
    "            # This could be the title of the document, name of the product, \n",
    "            # or item in your search index. If you don't have a title in \n",
    "            # your search index, leave this field blank.\n",
    "            # In this case the title field will be animal as it describes the type.\n",
    "            title_field=SemanticField(field_name=\"animal\"),\n",
    "            # Kevword fields should be a list of keywords. such as the tags on a document, \n",
    "            # or a descriptive term. such as the category of an item. \n",
    "            # Make sure to list kevword fields in order of priority because lower priority \n",
    "            # fields mav aet truncated or janored.\n",
    "            prioritized_keywords_fields=[SemanticField(field_name=\"name\")],\n",
    "            prioritized_content_fields=[SemanticField(field_name=\"song\")]\n",
    "        )\n",
    "    )]),\n",
    "    vector_search=VectorSearch(\n",
    "     algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=vector_config_name,\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            },            \n",
    "        )\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "# Create an index\n",
    "try:\n",
    "    # Check if an index called animals exists, if it does delete it and then create a new one\n",
    "    if azure_search_client.get_index(vector_index_name):\n",
    "        azure_search_client.delete_index(vector_index_name)\n",
    "\n",
    "except:\n",
    "    if ResourceNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    azure_search_client.create_index(vector_index)\n",
    "    vector_search_client = SearchClient(endpoint, vector_index_name, AzureKeyCredential(key))\n",
    "\n",
    "    # modify dataset such that all id fields are strings\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]['id'] = str(dataset[i]['id'])\n",
    "        vector_search_client.upload_documents(documents=[dataset[i]])\n",
    "except:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search and Print (Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_vector_search(query):\n",
    "    print('Searching for documents with query: ', query)\n",
    "    vector_query = generate_embeddings(query)\n",
    "    vector_search_client = SearchClient(endpoint, vector_index_name, AzureKeyCredential(key))\n",
    "\n",
    "    results = vector_search_client.search(\n",
    "        search_text=None,\n",
    "        vector=vector_query,\n",
    "        top_k=1,\n",
    "        vector_fields=\"animalVector\",\n",
    "        )\n",
    "                                        \n",
    "\n",
    "    # print message if no results are found\n",
    "    # if results.\n",
    "    #     print('No results found')\n",
    "\n",
    "    for result in results:\n",
    "        print(' Animal: ', result['animal'],\n",
    "              ', Name: ', result['name'],\n",
    "              ', Document id: ', result['id'], \n",
    "              ', Score: ', result['@search.score'],\n",
    "              )\n",
    "        # pprint(result, indent=4)\n",
    "        \n",
    "\n",
    "\n",
    "perform_vector_search('Oct')\n",
    "perform_vector_search('has tentacles') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
